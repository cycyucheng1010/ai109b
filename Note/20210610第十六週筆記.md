# 20210610第十六週
## 機器學習
* 簡介
  * 機器學習理論主要是設計和分析一些讓電腦可以自動「學習」的演算法。

![image](https://user-images.githubusercontent.com/62127656/121537026-24d64900-ca36-11eb-9ea3-5abb4ae49416.png)

## 蒙地卡羅方法 (Monte Carlo method)
* 基本概念
  1. 所求解的問題本身具有內在的隨機性，藉助電腦的運算能力可以直接類比這種隨機的過程
  2. 求解問題可以轉化為某種隨機分布的特徵數，比如隨機事件出現的機率，或者隨機變數的期望值。
  
  ![image](https://user-images.githubusercontent.com/62127656/121537551-9b734680-ca36-11eb-832a-6d5e5c0a966e.png)
## 馬可夫鏈 (Markov chain)
* 討論不是互相獨立的一些事件。
* 下一狀態的機率分布只能由當前狀態決定，在時間序列中它前面的事件均與之無關。
* 種具有狀態的隨機過程
* ex: 轉移矩陣的應用問題
 
![image](https://user-images.githubusercontent.com/62127656/121540325-fad25600-ca38-11eb-8fd8-a894c306c0e3.png)
![image](https://user-images.githubusercontent.com/62127656/121545085-c791c600-ca3c-11eb-978e-5049c6b15e41.png)
## 吉布斯採樣 (Gibbs sampling)
* 用於在難以直接採樣時從某一多變量概率分布中近似抽取樣本序列。
* 是統計學中用於馬爾科夫蒙特卡洛（MCMC）的一種算法
 
 ![image](https://user-images.githubusercontent.com/62127656/121542363-acbe5200-ca3a-11eb-8d99-8eb8b2f171e5.png)
 ![image](https://user-images.githubusercontent.com/62127656/121545009-b8127d00-ca3c-11eb-8f8a-6a8d3fe4f798.png)
## 隱藏式馬可夫模型 (Hidden Markov Model)
* 用來描述一個含有隱含未知參數的馬可夫過
* 從可觀察的參數中確定該過程的隱含參數，然後利用這些參數來作進一步的分析。
* ex: 假設一個病人每天來到診所並告訴醫生他的感覺。醫生相信病人的健康狀況如同一個離散馬可夫鏈。
 ![image](https://user-images.githubusercontent.com/62127656/121543360-6f0df900-ca3b-11eb-9c69-6c2b090e528a.png)
## 維特比演算法（Viterbi algorithm）
* 維特比演算法是高通創辦人 Viterbi 所設計的一個方法。
* 維特比演算法可以很快地計算《隱馬可夫模型》的最可能隱序列。
* 原本是用來去除通訊系統雜訊用的，後來在《語音辨識與自然語言處理領域》也很常被使用。
![image](https://user-images.githubusercontent.com/62127656/121547168-7a165880-ca3e-11eb-9a1b-31606acf875c.png)
![image](https://user-images.githubusercontent.com/62127656/121559857-8f44b480-ca49-11eb-94b8-11767b19aa8a.png)
## 最大期望演算法  （Expectation-maximization algorithm)
*  統計中被用於尋找，依賴於不可觀察的隱性變量的概率模型中，參數的最大似然估計。
  
![image](https://user-images.githubusercontent.com/62127656/121550520-64566280-ca41-11eb-8ced-a640c3b8840c.png)
![image](https://user-images.githubusercontent.com/62127656/121550664-80f29a80-ca41-11eb-8ed8-85a343e6d921.png)
1. θA和θB之初值可隨便設，雖不知實驗時是A還是B但可算出期望值。<br>
   ex: 第一次的期望值  
![image](https://user-images.githubusercontent.com/62127656/121556717-b352c680-ca46-11eb-9436-b69b6baedd21.png)

2. 再利用此機率去計算銅板正面及反面的期望值。<br>
ex: P(A) (#H, #T) = 0.45 (5H, 5T) = (2.25 H, 2.25T) ~ (2.2H, 2.2T) 
3. 將H和T加總可求出新的θA和θB<br>
![image](https://user-images.githubusercontent.com/62127656/121558726-7daedd00-ca48-11eb-82a7-0cf84ad4ddc8.png) 
4.按照以上循環找出最後的結果

![image](https://user-images.githubusercontent.com/62127656/121559770-789e5d80-ca49-11eb-818e-4db1eaf1598d.png)
## K-近鄰演算法
* 透過找出附近鄰居的分類定義來自己的類別。

![image](https://user-images.githubusercontent.com/62127656/121561595-3bd36600-ca4b-11eb-9c0c-c4a4e054d1b2.png)
## 決策樹(Decision Tree)
* 決策樹建立並用來輔助決策，是一種特殊的樹結構。
* 它是一個算法顯示的方法。決策樹經常在運籌學中使用，特別是在決策分析中，它幫助確定一個能最可能達到目標的策略。 

![image](https://user-images.githubusercontent.com/62127656/121563319-e1d3a000-ca4c-11eb-9964-93369680a93f.png)
![image](https://user-images.githubusercontent.com/62127656/121564034-9a99df00-ca4d-11eb-9be4-6c869da33056.png)

## 隨機森林(Random Forest)
* 近幾年隨機森林非常受到青睞，被運用在大量的機器學習應用中
* 隨機森林是一個包含多個決策樹的分類器，並且其輸出的類別是由個別樹輸出的類別的眾數而定。
* 隨機森林是由很多决策樹構成的，不同决策樹之間没有關聯。

![image](https://user-images.githubusercontent.com/62127656/121564216-cc12aa80-ca4d-11eb-8bf4-60de02c5445d.png)
![image](https://user-images.githubusercontent.com/62127656/121564184-c026e880-ca4d-11eb-9251-43e4787bc6de.png)
## 支援向量機 Support Vector Machine (SVM)
* 是一種二分類模型
* 在分類與迴歸分析中分析資料的監督式學習模型與相關的學習演算法。
![image](https://user-images.githubusercontent.com/62127656/121566218-ddf54d00-ca4f-11eb-913f-c53f515aba60.png)
